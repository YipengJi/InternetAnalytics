{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *J*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Dennis Gankin*\n",
    "* *Name 2*\n",
    "* *Name 3*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from utils import load_pkl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "tf_matrix = load_pkl('tfidf.pkl')\n",
    "terms = load_pkl('terms.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model following the mllib docs\n",
    "tf_dataframe=sc.parallelize(tf_matrix.T)\n",
    "\n",
    "data=tf_dataframe.map(lambda line: Vectors.dense([float(x) for x in line]))\n",
    "corpus= data.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "ldaModel = LDA.train(corpus, k=10, optimizer='online')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def topic_descriptions(model, num_topics=10, num_labels=10):\n",
    "    topics=model.topicsMatrix()\n",
    "    \n",
    "    for topic in range(num_topics):\n",
    "        print(\"Topic \" + str(topic) + \":\")\n",
    "        top_word_ids = np.argsort(topics[:,topic])[::-1][0:num_labels]\n",
    "        labels = []\n",
    "        \n",
    "        for word_id in top_word_ids:\n",
    "            labels.append(terms[word_id])\n",
    "        print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['energi', 'convex', 'solar', 'convers', 'hydraul', 'renew', 'balanc', 'optim', 'thermodynam', 'cell']\n",
      "Topic 1:\n",
      "['nmr', 'bioengin', 'nuclear', 'laboratori', 'magnet', 'wetlab', 'obtain', 'sv', 'neurosci', 'spectroscopi']\n",
      "Topic 2:\n",
      "['imag', 'optic', 'linear', 'protein', 'process', 'materi', 'model', 'chemic', 'applic', 'numer']\n",
      "Topic 3:\n",
      "['electron', 'transfer', 'heat', 'philosoph', 'speaker', 'seminar', 'turbul', 'flow', 'quantum', 'mass']\n",
      "Topic 4:\n",
      "['cell', 'project', 'manag', 'data', 'group', 'risk', 'network', 'innov', 'present', 'biolog']\n",
      "Topic 5:\n",
      "['tem', 'microscopi', 'media', 'multimedia', 'imag', 'microscop', 'user', 'privaci', 'sem', 'transmiss']\n",
      "Topic 6:\n",
      "['polici', 'suppli', 'fib', 'cancer', 'breast', 'sem', 'sti', 'lithographi', 'situ', 'rsa']\n",
      "Topic 7:\n",
      "['recognit', 'regress', 'semiconductor', 'speech', 'price', 'biometr', 'markov', 'stochast', 'model', 'neural']\n",
      "Topic 8:\n",
      "['food', 'architectur', 'urban', 'snow', 'studio', 'plasma', 'territori', 'water', 'spatial', 'laba']\n",
      "Topic 9:\n",
      "['circuit', 'analog', 'power', 'reactor', 'biosens', 'voltag', 'cmo', 'amplifi', 'chip', 'mix']\n"
     ]
    }
   ],
   "source": [
    "topic_descriptions(ldaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: How does it compare with LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try for alphas and betas\n",
    "params = [0.1, 1.0, 10.0, 1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameters_LDA(corpus, alpha=6.0,beta=1.01,k=10):\n",
    "\n",
    "    if type(alpha)==list:\n",
    "        print(\"beta =\",beta,\"\\n\")\n",
    "        for a in alpha:\n",
    "            print(\"\\n alpha =\", a)\n",
    "            model = LDA.train(corpus, k=k, seed=1, topicConcentration=beta, docConcentration=a, optimizer='online')\n",
    "            topic_descriptions(model,num_topics=k)\n",
    "    elif type(beta)==list:\n",
    "        print(\"alpha =\",alpha,\"\\n\")\n",
    "        for b in beta:\n",
    "            print(\"\\nbeta =\",b)\n",
    "            model = LDA.train(corpus, k=k, seed=1, topicConcentration=b, docConcentration=alpha, optimizer='online')\n",
    "            topic_descriptions(model,num_topics=k)\n",
    "    else:\n",
    "        print(\"alpha =\",alpha)\n",
    "        print(\"beta =\",beta,\"\\n\")\n",
    "        model = LDA.train(corpus, k=k, seed=1, topicConcentration=beta, docConcentration=alpha, optimizer='online')\n",
    "        topic_descriptions(model,num_topics=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta = 1.01 \n",
      "\n",
      "\n",
      " alpha = 0.1\n",
      "Topic 0:\n",
      "['project', 'data', 'research', 'group', 'materi', 'report', 'plan', 'manag', 'busi', 'object']\n",
      "Topic 1:\n",
      "['acoust', 'algebra', 'lie', 'curv', 'ring', 'neuroprosthes', 'neuroprosthesi', 'invas', 'tech', 'geometri']\n",
      "Topic 2:\n",
      "['mx', 'mse', 'crack', 'cardiac', 'arteri', 'ancient', 'ray', 'venou', 'blood', 'degrad']\n",
      "Topic 3:\n",
      "['risk', 'linear', 'statist', 'flow', 'model', 'probabl', 'control', 'robot', 'algorithm', 'numer']\n",
      "Topic 4:\n",
      "['magnet', 'electron', 'circuit', 'imag', 'sensor', 'devic', 'cmo', 'digit', 'nois', 'filter']\n",
      "Topic 5:\n",
      "['reaction', 'reactor', 'snow', 'chemic', 'energi', 'heat', 'kinet', 'thermodynam', 'water', 'chemistri']\n",
      "Topic 6:\n",
      "['protein', 'cell', 'solar', 'doctor', 'edm', 'motil', 'sensit', 'kinas', 'tem', 'assay']\n",
      "Topic 7:\n",
      "['laser', 'optic', 'radiat', 'photon', 'light', 'electromagnet', 'shield', 'fiber', 'grate', 'game']\n",
      "Topic 8:\n",
      "['food', 'architectur', 'wast', 'studio', 'urban', 'drug', 'wood', 'code', 'ferment', 'build']\n",
      "Topic 9:\n",
      "['convex', 'planet', 'planetari', 'avion', 'datacent', 'systemc', 'systemverilog', 'thousand', 'rtl', 'warehous']\n",
      "\n",
      " alpha = 1.0\n",
      "Topic 0:\n",
      "['busi', 'steel', 'fractur', 'seismic', 'crack', 'structur', 'later', 'week', 'market', 'financ']\n",
      "Topic 1:\n",
      "['lie', 'algebra', 'curv', 'ring', 'geometri', 'market', 'arriv', 'riemann', 'commut', 'tech']\n",
      "Topic 2:\n",
      "['cardiac', 'arteri', 'ancient', 'ray', 'venou', 'degrad', 'blood', 'wall', 'biomechan', 'paint']\n",
      "Topic 3:\n",
      "['risk', 'linear', 'statist', 'model', 'probabl', 'numer', 'flow', 'algorithm', 'theori', 'space']\n",
      "Topic 4:\n",
      "['imag', 'electron', 'magnet', 'circuit', 'sensor', 'devic', 'filter', 'cmo', 'digit', 'nois']\n",
      "Topic 5:\n",
      "['reaction', 'reactor', 'snow', 'chemic', 'protein', 'kinet', 'heat', 'thermodynam', 'transport', 'mass']\n",
      "Topic 6:\n",
      "['solar', 'sensit', 'dye', 'databas', 'excit', 'cell', 'emit', 'photo', 'video', 'queri']\n",
      "Topic 7:\n",
      "['laser', 'optic', 'light', 'radiat', 'photon', 'fiber', 'waveguid', 'shield', 'grate', 'electromagnet']\n",
      "Topic 8:\n",
      "['project', 'architectur', 'food', 'present', 'research', 'process', 'data', 'develop', 'group', 'engin']\n",
      "Topic 9:\n",
      "['neuroprosthes', 'neuroprosthet', 'invas', 'neuroprosthesi', 'neurorehabilit', 'cn', 'limb', 'spinal', 'neural', 'stimul']\n",
      "\n",
      " alpha = 10.0\n",
      "Topic 0:\n",
      "['risk', 'architectur', 'urban', 'market', 'studio', 'map', 'busi', 'polici', 'suppli', 'digit']\n",
      "Topic 1:\n",
      "['imag', 'speech', 'model', 'statist', 'mechan', 'algebra', 'theori', 'space', 'basic', 'digit']\n",
      "Topic 2:\n",
      "['materi', 'energi', 'imag', 'ancient', 'absorpt', 'spectroscopi', 'ray', 'degrad', 'model', 'wall']\n",
      "Topic 3:\n",
      "['flow', 'numer', 'equat', 'fluid', 'ah', 'dynam', 'heat', 'particl', 'simul', 'finit']\n",
      "Topic 4:\n",
      "['sensor', 'circuit', 'devic', 'electron', 'robot', 'magnet', 'filter', 'nois', 'cmo', 'materi']\n",
      "Topic 5:\n",
      "['snow', 'reactor', 'reaction', 'chemic', 'kinet', 'model', 'fractur', 'transport', 'catalysi', 'heat']\n",
      "Topic 6:\n",
      "['steel', 'seismic', 'structur', 'model', 'crack', 'reactor', 'fractur', 'cell', 'reaction', 'laser']\n",
      "Topic 7:\n",
      "['optic', 'laser', 'reaction', 'control', 'imag', 'light', 'cell', 'motil', 'mechan', 'process']\n",
      "Topic 8:\n",
      "['food', 'test', 'project', 'week', 'report', 'research', 'lab', 'data', 'process', 'engin']\n",
      "Topic 9:\n",
      "['ture', 'theorem', 'space', 'protein', 'linear', 'fourier', 'theori', 'recurs', 'hilbert', 'model']\n",
      "\n",
      " alpha = 1000.0\n",
      "Topic 0:\n",
      "['data', 'model', 'project', 'process', 'energi', 'problem', 'risk', 'chemic', 'class', 'flow']\n",
      "Topic 1:\n",
      "['model', 'imag', 'materi', 'mechan', 'data', 'project', 'risk', 'digit', 'comput', 'problem']\n",
      "Topic 2:\n",
      "['materi', 'data', 'model', 'process', 'energi', 'present', 'project', 'problem', 'reactor', 'flow']\n",
      "Topic 3:\n",
      "['model', 'flow', 'process', 'energi', 'system', 'control', 'imag', 'mechan', 'week', 'base']\n",
      "Topic 4:\n",
      "['model', 'project', 'process', 'imag', 'exercis', 'present', 'research', 'materi', 'mechan', 'energi']\n",
      "Topic 5:\n",
      "['model', 'process', 'materi', 'architectur', 'linear', 'chemic', 'flow', 'project', 'base', 'data']\n",
      "Topic 6:\n",
      "['project', 'model', 'process', 'present', 'electron', 'architectur', 'energi', 'data', 'plan', 'week']\n",
      "Topic 7:\n",
      "['process', 'control', 'data', 'optic', 'project', 'materi', 'model', 'engin', 'electron', 'risk']\n",
      "Topic 8:\n",
      "['model', 'project', 'process', 'control', 'system', 'materi', 'evalu', 'comput', 'test', 'basic']\n",
      "Topic 9:\n",
      "['energi', 'model', 'theori', 'control', 'test', 'digit', 'comput', 'mechan', 'process', 'structur']\n"
     ]
    }
   ],
   "source": [
    "parameters_LDA(corpus,alpha=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: how does it impact the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 6.0 \n",
      "\n",
      "\n",
      "beta = 0.1\n",
      "Topic 0:\n",
      "['risk', 'market', 'busi', 'laser', 'polici', 'financ', 'financi', 'suppli', 'price', 'case']\n",
      "Topic 1:\n",
      "['speech', 'algebra', 'imag', 'audio', 'video', 'acoust', 'sound', 'curv', 'tp', 'lie']\n",
      "Topic 2:\n",
      "['ancient', 'materi', 'degrad', 'absorpt', 'tem', 'ray', 'sensit', 'spectroscopi', 'paint', 'damag']\n",
      "Topic 3:\n",
      "['quantum', 'equat', 'molecular', 'approxim', 'phase', 'flow', 'dynam', 'arteri', 'statement', 'function']\n",
      "Topic 4:\n",
      "['circuit', 'electron', 'magnet', 'devic', 'sensor', 'cmo', 'nois', 'filter', 'imag', 'optic']\n",
      "Topic 5:\n",
      "['snow', 'reactor', 'protein', 'reaction', 'chemic', 'kinet', 'cell', 'radiat', 'heat', 'thermodynam']\n",
      "Topic 6:\n",
      "['crack', 'fractur', 'mx', 'mse', 'structur', 'cell', 'steel', 'model', 'mechan', 'electron']\n",
      "Topic 7:\n",
      "['optic', 'light', 'fluoresc', 'imag', 'organ', 'laser', 'reaction', 'secur', 'biophoton', 'biolog']\n",
      "Topic 8:\n",
      "['project', 'process', 'data', 'model', 'test', 'food', 'comput', 'control', 'robot', 'week']\n",
      "Topic 9:\n",
      "['steel', 'ture', 'seismic', 'recurs', 'locomot', 'plastic', 'theorem', 'neuroprosthet', 'neural', 'brain']\n",
      "\n",
      "beta = 1.0\n",
      "Topic 0:\n",
      "['risk', 'market', 'busi', 'polici', 'laser', 'financ', 'financi', 'price', 'portfolio', 'case']\n",
      "Topic 1:\n",
      "['speech', 'algebra', 'imag', 'curv', 'audio', 'sound', 'acoust', 'tp', 'mpeg', 'lie']\n",
      "Topic 2:\n",
      "['ancient', 'degrad', 'absorpt', 'ray', 'tem', 'materi', 'spectroscopi', 'paint', 'sensit', 'imag']\n",
      "Topic 3:\n",
      "['quantum', 'equat', 'approxim', 'molecular', 'arteri', 'dynam', 'kohn', 'polymer', 'flow', 'biomechan']\n",
      "Topic 4:\n",
      "['circuit', 'electron', 'magnet', 'devic', 'sensor', 'cmo', 'nois', 'imag', 'optic', 'filter']\n",
      "Topic 5:\n",
      "['snow', 'protein', 'reactor', 'reaction', 'cell', 'chemic', 'radiat', 'kinet', 'drug', 'motil']\n",
      "Topic 6:\n",
      "['steel', 'crack', 'mx', 'seismic', 'fractur', 'mse', 'brace', 'aisc', 'mrf', 'structur']\n",
      "Topic 7:\n",
      "['optic', 'imag', 'light', 'fluoresc', 'secur', 'reaction', 'laser', 'organ', 'equat', 'kinet']\n",
      "Topic 8:\n",
      "['project', 'process', 'data', 'model', 'test', 'control', 'comput', 'food', 'week', 'engin']\n",
      "Topic 9:\n",
      "['ture', 'recurs', 'theorem', 'locomot', 'neuroprosthet', 'arithmet', 'neural', 'plastic', 'brain', 'neuroprosthes']\n",
      "\n",
      "beta = 10.0\n",
      "Topic 0:\n",
      "['busi', 'risk', 'servic', 'financi', 'project', 'ea', 'model', 'seam', 'bpel', 'bpmn']\n",
      "Topic 1:\n",
      "['imag', 'snow', 'model', 'secur', 'algebra', 'mechan', 'cell', 'protein', 'acoust', 'risk']\n",
      "Topic 2:\n",
      "['snow', 'materi', 'protein', 'model', 'energi', 'electron', 'data', 'ray', 'physic', 'mechan']\n",
      "Topic 3:\n",
      "['financi', 'flow', 'molecular', 'electron', 'statement', 'mechan', 'protein', 'dynam', 'equat', 'model']\n",
      "Topic 4:\n",
      "['circuit', 'cmo', 'devic', 'nois', 'semiconductor', 'transistor', 'electron', 'analog', 'ccd', 'memori']\n",
      "Topic 5:\n",
      "['snow', 'protein', 'model', 'chemic', 'ray', 'busi', 'thermodynam', 'chip', 'cell', 'diffract']\n",
      "Topic 6:\n",
      "['protein', 'electron', 'model', 'project', 'cell', 'snow', 'diffract', 'structur', 'ray', 'data']\n",
      "Topic 7:\n",
      "['imag', 'electron', 'optic', 'protein', 'secur', 'snow', 'equat', 'control', 'mechan', 'ray']\n",
      "Topic 8:\n",
      "['model', 'process', 'materi', 'project', 'data', 'energi', 'control', 'comput', 'architectur', 'present']\n",
      "Topic 9:\n",
      "['ture', 'recurs', 'arithmet', 'protein', 'theorem', 'peano', 'gödel', 'incomplet', 'energi', 'syntax']\n",
      "\n",
      "beta = 1000.0\n",
      "Topic 0:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'data', 'mechan', 'control', 'problem', 'flow']\n",
      "Topic 1:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'data', 'mechan', 'control', 'imag', 'problem']\n",
      "Topic 2:\n",
      "['model', 'process', 'materi', 'project', 'energi', 'data', 'mechan', 'control', 'problem', 'flow']\n",
      "Topic 3:\n",
      "['model', 'process', 'materi', 'energi', 'project', 'data', 'mechan', 'control', 'flow', 'problem']\n",
      "Topic 4:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'data', 'mechan', 'control', 'imag', 'flow']\n",
      "Topic 5:\n",
      "['model', 'process', 'materi', 'project', 'energi', 'data', 'mechan', 'control', 'flow', 'problem']\n",
      "Topic 6:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'data', 'control', 'mechan', 'problem', 'present']\n",
      "Topic 7:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'data', 'control', 'mechan', 'problem', 'imag']\n",
      "Topic 8:\n",
      "['model', 'process', 'project', 'materi', 'energi', 'wast', 'data', 'control', 'mechan', 'problem']\n",
      "Topic 9:\n",
      "['model', 'process', 'materi', 'energi', 'project', 'data', 'mechan', 'control', 'problem', 'comput']\n"
     ]
    }
   ],
   "source": [
    "parameters_LDA(corpus,beta=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: how does it impact the topuics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chose k as number of sections at EPF\n",
    "\n",
    "\"\"\"Architecture, Civil and Environmental Engineering ENAC,\n",
    "Basic Sciences SB,\n",
    "Engineering STI,\n",
    "Computer and Communication Sciences IC,\n",
    "Life Sciences SV,\n",
    "Management of Technology CDM,\n",
    "College of Humanities CDH\"\"\"\n",
    "k=7\n",
    "#chose alpha beta from above??\n",
    "#TODO: make and axplain alpha beta choice..\n",
    "alpha=1.5\n",
    "beta=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1.5\n",
      "beta = 0.01 \n",
      "\n",
      "Topic 0:\n",
      "['project', 'food', 'research', 'data', 'present', 'manag', 'architectur', 'group', 'risk', 'develop']\n",
      "Topic 1:\n",
      "['algebra', 'lie', 'curv', 'neuroprosthes', 'ring', 'invas', 'neuroprosthesi', 'geometri', 'de', 'planet']\n",
      "Topic 2:\n",
      "['solar', 'absorpt', 'mx', 'cardiac', 'materi', 'ancient', 'ray', 'light', 'arteri', 'sensit']\n",
      "Topic 3:\n",
      "['linear', 'statist', 'probabl', 'numer', 'model', 'robot', 'flow', 'algorithm', 'control', 'space']\n",
      "Topic 4:\n",
      "['imag', 'sensor', 'electron', 'magnet', 'circuit', 'optic', 'devic', 'digit', 'filter', 'cmo']\n",
      "Topic 5:\n",
      "['reactor', 'reaction', 'snow', 'energi', 'chemic', 'protein', 'kinet', 'heat', 'transport', 'thermodynam']\n",
      "Topic 6:\n",
      "['video', 'cell', 'secur', 'verif', 'cancer', 'speech', 'tumor', 'vhdl', 'mpeg', 'laboratori']\n"
     ]
    }
   ],
   "source": [
    "parameters_LDA(corpus,alpha=alpha,beta=beta,k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|page_id|               title|              tokens|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|   Áedán mac Gabráin|[áedán, mac, gabr...|\n",
      "|      2|       Åland Islands|[åland, islandssc...|\n",
      "|      3|       Édouard Manet|[édouard, manetsc...|\n",
      "|      4|                Éire|[éireschools, wik...|\n",
      "|      5|     Évariste Galois|[évariste, galois...|\n",
      "|      6|Óengus I of the P...|[óengus, pictssch...|\n",
      "|      7|€2 commemorative ...|[€, commemorative...|\n",
      "|      8|          0 (number)|[numberschools, w...|\n",
      "|      9|   10 Downing Street|[downing, streets...|\n",
      "|     10|        10th century|[centuryschools, ...|\n",
      "|     11|        11th century|[centuryschools, ...|\n",
      "|     12|        12th century|[centuryschools, ...|\n",
      "|     13|        13th century|[centuryschools, ...|\n",
      "|     14|        14th century|[centuryschools, ...|\n",
      "|     15|        15th century|[centuryschools, ...|\n",
      "|     16|            16 Cygni|[cygnischools, wi...|\n",
      "|     17|        16th century|[centuryschools, ...|\n",
      "|     18|                1750|[schools, wikiped...|\n",
      "|     19|                1751|[schools, wikiped...|\n",
      "|     20|                1752|[schools, wikiped...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wikipedia_raw = sc.textFile('/ix/wikipedia-for-schools.txt')\n",
    "wikipedia_df = wikipedia_raw.map(lambda l: Row(**dict(json.loads(l)))).toDF()\n",
    "wikipedia_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\")\n",
    "model = cv.fit(wikipedia_df)\n",
    "wikipedia_count_df = model.transform(wikipedia_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_corpus = wikipedia_count_df.select(\"page_id\", \"features\").map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://en.wikipedia.org/wiki/Category:Main_topic_classifications --- 22 topics?\n",
    "#or 12?\n",
    "\n",
    "def topic_descriptions(model, num_topics=10, num_labels=10):\n",
    "    topics=model.topicsMatrix()\n",
    "    terms=model.vocabulary\n",
    "    \n",
    "    for topic in range(num_topics):\n",
    "        print(\"Topic \" + str(topic) + \":\")\n",
    "        top_word_ids = np.argsort(topics[:,topic])[::-1][0:num_labels]\n",
    "        labels = []\n",
    "        \n",
    "        for word_id in top_word_ids:\n",
    "            labels.append(terms[word_id])\n",
    "        print(labels)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 1.5\n",
      "beta = 0.01 \n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o632.trainLDAModel.\n: java.lang.OutOfMemoryError: GC overhead limit exceeded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-5d05ae1b9873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters_LDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_corpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-90-daa065733852>\u001b[0m in \u001b[0;36mparameters_LDA\u001b[0;34m(corpus, alpha, beta, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopicConcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocConcentration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtopic_descriptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/pyspark/mllib/clustering.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, rdd, k, maxIterations, docConcentration, topicConcentration, seed, checkpointInterval, optimizer)\u001b[0m\n\u001b[1;32m    802\u001b[0m         model = callMLlibFunc(\"trainLDAModel\", rdd, k, maxIterations,\n\u001b[1;32m    803\u001b[0m                               \u001b[0mdocConcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopicConcentration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                               checkpointInterval, optimizer)\n\u001b[0m\u001b[1;32m    805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mLDAModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallMLlibFunc\u001b[0;34m(name, *args)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonMLLibAPI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallJavaFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/pyspark/mllib/common.py\u001b[0m in \u001b[0;36mcallJavaFunc\u001b[0;34m(sc, func, *args)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m\"\"\" Call Java Function \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_py2java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_java2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o632.trainLDAModel.\n: java.lang.OutOfMemoryError: GC overhead limit exceeded\n"
     ]
    }
   ],
   "source": [
    "parameters_LDA(wiki_corpus,alpha=1.5,beta=0.01,k=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
